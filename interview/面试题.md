***先定一个短期目标***
* 运维高级工程师需要具备以下一些技能：
  * 系统管理：熟练掌握各种操作系统的安装、配置、维护和优化，如 Linux、Unix、Windows 等。
  * 网络管理：具备良好的网络基础知识，包括 TCP/IP 协议、路由、交换机、防火墙等。
  * 数据库管理：熟悉各种数据库系统，如 MySQL、Oracle、SQL Server 等，并具备对数据库进行管理、维护和优化的能力。
  * 监控工具：熟练使用各种监控工具，如 Nagios、Zabbix 等，以保证系统的稳定运行。
  * 自动化运维：熟悉各种自动化运维工具，如 Ansible、Puppet 等，以提高工作效率。
  * 编程语言：具备至少一门编程语言，如 Python、Shell、Java 等，以方便编写脚本程序。
  * 文档撰写：具备良好的文档撰写能力，以保证文档的整洁、易懂和完整。
  * 沟通协调：具备良好的沟通能力和团队合作精神，以方便与团队成员和客户进行有效沟通。
  * 问题分析：具备良好的问题分析能力

# 面试问题
## k8s方面

* 如何管理k8s集群
```
作为运维工程师，管理Kubernetes集群需要遵循一些基本原则和步骤：

安装和配置：确保集群安装并配置正确，确保所有节点处于可用状态。
集群监控：使用工具（例如Prometheus）监控集群的资源使用情况，以确保其正常运行。
生命周期管理：通过对应用、服务和容器的生命周期管理来确保集群中的所有资源运行正常。
访问控制：确保集群的安全性，限制对集群的访问和控制。
资源管理：管理集群中的资源，包括内存、磁盘空间等，以确保集群能够满足业务需求。
备份和恢复：定期备份集群数据，以便在灾难情况下进行恢复。
更新和升级：管理集群的更新和升级，以确保其保持最新状态。

这些是管理Kubernetes集群的基本步骤。如果您对Kubernetes集群管理感兴趣，可以考虑获取Kubernetes的相关认证，以确保您具备所需的知识和技能。
```

* k8s集群如何保证高可用
```
 Kubernetes 通过心跳检测机制来确定节点是否失效。如果节点失效，Kubernetes 会自动将其上的工作负载迁移到其他可用节点。
 Kubernetes 提供了Leader 选举机制，用以确保多个控制器的实例同时运行，并且只有Leader 实例提供真正的服务
```
* k8s cicd发布从开发提交代码到上线运维在每个部分起到的作用是什么我们需要关注哪些点
```
Kubernetes CICD 是指使用 Continuous Integration 和 Continuous Deployment 的方式，在 Kubernetes 集群上部署和管理应用程序。
CICD 过程通常分为以下几个部分：
开发：开发人员编写代码，并将其提交到代码仓库。
构建：构建系统从代码仓库拉取代码，并使用打包工具（如 Docker）打包应用程序。
测试：自动化测试系统对打包的应用程序进行测试，以确保代码符合质量标准。
部署：如果测试通过，应用程序将部署到 Kubernetes 集群。
运维：应用程序在生产环境中运行，运维团队负责监控和维护应用程序。
```
* k8s集群中某台机器需要关机或者维护我们如何优雅的操作
```
Kubernetes 集群中 master 节点或 node 节点关机或维护时，需要保证关机/维护操作对应用程序的影响尽可能小。以下是一些优雅的操作方法：
关闭 node 节点：使用 kubectl drain 命令可以将 node 上的工作负载平滑迁移到其他 node 上。
维护 master 节点：通常可以使用多个 master 节点，在一个 master 节点上执行维护操作时，其他 master 节点可以继续提供服务。
使用可伸缩的部署方式：使用 ReplicaSet、Deployment 等可伸缩的部署方式，可以在关机/维护期间保证应用程序的正常运行。

需要注意的是，具体的优雅关机/维护操作方式可能因 Kubernetes 集群的架构、应用程序的部署方式等因素不同而有所不同。
因此，需要根据实际情况灵活选择和使用相应的操作方法。
```
* k8s Flannel（基于隧道） 和 Calico （基于路由）
```
Flannel 首先创建了一个名为 flannel0 的网桥，而且这个网桥的一端连接 docker0 的网桥，另一端连接一个名为 flanneld 的服务进程。
Flanneld 进程并不简单，它首先上连 etcd，利用 etcd 来管理可分配的 IP 地址段资源，同时监控 etcd 中每个 Pod 的实际地址，
并在内存中建立了一个 Pod 节点路由表；然后下连 docker0 和物理网络，使用内存中的 Pod 节点路由表，将 docker0 发给它的数据包包装起来，
利用物理网络的连接将数据包投递到目标 flanneld 上，从而完成 pod 到 pod 之间的直接的地址通信。

Flannel 实现了对 Kubernetes 网络的支持，但是它引入了多个网络组件，在网络通信时需要转到 flannel0 网络接口，
再转到用户态的 flanneld 程序，到对端后还需要走这个过程的反过程，所以也会引入一些网络的时延损耗。
另外 Flannel 默认的底层通信协议是 UDP。UDP 本身是非可靠协议，虽然两端的 TCP 实现了可靠传输，
但在大流量、高并发应用场景下还需要反复调试，确保不会出现传输质量的问题。特别是对网络依赖重的应用，需要评估对业务的影响。


Calico 作为一款针对企业级数据中心的虚拟网络工具，借助 BGP、路由表和 iptables，实现了一个无需解包封包的三层网络，并且有调试简单的特点。
```
* TPS（每秒事务数） 和qps （每秒查询率）
```
区别:
TPS即每秒处理事务数，包括了
1）用户请求服务器
2）服务器自己的内部处理
3）服务器返回给用户

QPS基本类似于Tps，但是不同的是，对于一个页面的一次访问，形成一个Tps；但一次页面请求，可能产生多次对服务器的请求，服务器对这些请求，就可计入“Qps”之中。
例如：访问一个页面会请求服务器3次，一次放，产生一个“T”，产生3个“Q”

HPS：Hits per Second 每秒点击次数
是指在一秒钟的时间内用户对Web页面的链接、提交按钮等点击总和。 它一般和TPS成正比关系，是B/S系统中非常重要的性能指标之一。
```
* k8s 巨大流量时如何优雅的发布程序
```
使用部署控制器：部署控制器，如Deployment、StatefulSet、DaemonSet，可以管理Pod的生命周期和更新。
利用滚动更新：通过更新一部分Pod，再等待运行状态稳定，再更新下一部分Pod。
利用服务策略：使用Kubernetes服务策略，如滚动更新和重新导向流量，可以确保程序正常运行。
状态监控：使用监控工具，如Prometheus、Grafana等，可以查看Pod的状态，并在发生错误时立即响应。
自动回滚：通过设置Pod的生命周期钩子，可以在程序出现错误时自动回滚到上一个版本
```
* requests 和 limits 
```
requests定义了对应容器需要的最小资源量
limits定义了这个容器最大可以消耗的资源上限，防止过量消耗资源导致资源短缺甚至宕机

节点资源不足时，会触发自动驱逐，将一些低优先级的 Pod 删除掉以释放资源让节点自愈。
没有设置 request，limit 的 Pod 优先级最低，容易被驱逐；request 不等于 limit 的其次； 
request 等于 limit 的 Pod 优先级较高，不容易被驱逐。
所以如果是重要的线上应用，不希望在节点故障时被驱逐导致线上业务受影响，
就建议将 request 和 limit 设成一致。
```
* 运维需要备份k8s中哪些东西如何备份 遇到问题如何恢复
```
备份 Kubernetes 集群的重要组件包括：
1.etcd 存储库：它存储了 Kubernetes 集群的所有配置数据和状态数据，如 Pod 状态，服务映射，配置数据等。
2.配置文件：这包括 kube-apiserver、kube-controller-manager 和 kube-scheduler 的配置文件。
3.TLS 证书：这些证书用于加密 Kubernetes 集群的通信。

下面是备份这些组件的一般步骤：
备份 etcd 存储库：您可以使用 etcdctl 工具进行备份，并将存储库导出为 tar 归档文件。
备份配置文件：您可以在系统上备份配置文件，并将它们复制到备份位置。
备份证书：您可以在系统上备份证书，并将它们复制到备份位置。
在遇到问题时进行恢复，您可以从备份中还原这些组件，并使用它们恢复集群。

恢复 etcd 存储库：您可以使用 etcdctl 工具恢复存储库，并从 tar 归档文件中导入数据。
恢复配置文件：您可以从备份中还原配置文件，并将它们复制回系统。
恢复证书：您可以从备份中还原证书，并将它们复制回系统。
```
***在恢复过程中，您可能需要重新启动一些组件，以确保它们正常工作。
此外，请确保在恢复前终止集群中的所有组件，以避免在恢复数据时发生冲突。
总而言之，备份和恢复 Kubernetes 集群是一项重要任务，需要认真考虑。***

* 在 Kubernetes 集群中，高可用的保证通常通过使用多个节点和容器副本来实现。
```
1.使用多个节点：在 Kubernetes 集群中，可以通过多个节点分布容器副本，以确保在单个节点出现故障时，可以继续运行其他节点上的容器副本。
2.容器副本：Kubernetes 支持在单个集群中运行多个容器副本。这些副本可以分布在多个节点上，以确保即使单个容器出现故障，也可以通过其他副本继续提供服务。

在遇到流量峰值超过了集群承受性时，可以采取以下措施：
1.动态扩展：Kubernetes 支持通过 Horizontal Pod Autoscaler (HPA) 动态扩展容器副本数量，以应对流量的增加。
2.负载均衡：Kubernetes 支持通过使用负载均衡器，如 NGINX 或者 Istio，对流量进行分发。
3.节点扩展：如果遇到流量峰值超过了集群承受性时，可以考虑扩展集群节点数量，以增加集群的计算能力。
```
* k8s集群保证高可用的底层逻辑，集群如何知道master或者node节点机器是否正常，如果异常集群又会做什么操作
```
k8s集群中的所有节点，包括master和node，都会定期地发送心跳（heartbeat）信息到etcd数据存储中。etcd记录了每个节点的当前状态，并且可以在需要时被其他节点查询。
如果某个master或node节点因为某些原因不再能够发送心跳信息，那么其他节点将认为该节点已经挂掉。此时，etcd数据存储会将该节点的状态设置为不可用。

如果一个master节点挂掉，那么其他节点会开始选举一个新的master节点。如果一个node节点挂掉，那么k8s会将其上的容器重新分配到其他node节点上。
这样，k8s集群就能保证高可用。
```
* Kubernetes 中的有状态服务和无状态服务是两个不同的概念。
```
有状态服务（stateful service）是指有持久存储的服务，这种服务通常需要持久化存储，如数据库或消息队列等。有状态服务通常需要保留每个实例的状态，并在重新启动时保留数据。
无状态服务（stateless service）是指没有持久存储的服务，例如 Web 应用程序或网关等。无状态服务通常不需要保留状态，因此可以在不同的实例间轻松地进行水平扩展和负载平衡。

在部署时，有状态服务需要注意以下几点：
1.存储：需要为有状态服务配置持久化存储，以保留数据。
2.唯一性：每个实例的状态必须是唯一的，因此需要对实例进行命名或使用其他方法来确保它们是唯一的。
3.可靠性：因为有状态服务的数据是持久的，因此必须保证它们的可靠性。这可以通过备份和恢复等措施来实现。
无状态服务的部署相对简单，因为它们不需要考虑数据存储和实例唯一
```

## 中间件以及数据库
### mysql
* 主从同步原理
```
MySQL 的主从复制工作过程大致如下：
从库生成两个线程，一个 I/O 线程，一个 SQL 线程;
I/O 线程去请求主库的 binlog，并将得到的 binlog 日志写到 relay log(中继日志) 文件中;
主库会生成一个 log dump 线程，用来给从库 I/O 线程传 binlog;
SQL 线程会读取 relay log 文件中的日志，并解析成具体操作，来实现主从的操作一致，而最终数据一致;

MySQL 建立请求的主从的详细流程如下：
当从服务器连接主服务器时，主服务器会创建一个 log dump 线程，用于发送 binlog 的内容。在读取 binlog 的内容的操作中，会对象主节点上的 binlog 加锁，当读取完成并发送给从服务器后解锁。
当从节点上执行 start slave 命令之后，从节点会创建一个 IO 线程用来连接主节点，请求主库中更新 binlog。IO 线程接收主节点 binlog dump 进程发来的更新之后，保存到 relay-log 中。
从节点 SQL 线程负责读取 realy-log 中的内容，解析成具体的操作执行，最终保证主从数据的一致性。
```
* MySQL主从复制状态如何查看，如何判断是否同步
```
你可以使用以下命令查询这些值：
MySQL主从复制是基于日志的，查看主从是否同步，你可以查询两个值：
主服务器上的二进制日志文件的当前位置（Master_Log_File）和已经执行的日志位置（Read_Master_Log_Pos）。
从服务器上执行的二进制日志文件的位置（Relay_Master_Log_File）和已经执行的位置（Exec_Master_Log_Pos）。

如果两个位置完全一致，则说明主从已经同步。
你可以使用以下命令查询这些值：
SHOW SLAVE STATUS\G

```
* 什么情况下会造成mysql主从同步慢或者主从同步异常 怎么处理
```
1.MySQL主从同步慢或异常的原因有很多，具体取决于情况。一些常见的原因包括：
2.网络问题：网络延迟或丢包可能会导致主从同步变慢。
3.数据库负载过高：如果主服务器处理大量请求，可能会导致同步变慢。
4.binlog日志缓存不足：如果binlog缓存空间不够，需要等待binlog缓存释放以更新数据。
5.数据同步线程的限制：如果设置了最大同步线程数，这可能导致同步变慢。
6.数据冲突：如果在从服务器上执行了不与主服务器同步的更改，可能会导致数据冲突。

要解决这些问题，您可以尝试以下方法：
1.检查网络：检查网络延迟和丢包，以确保主从之间的网络连接良好。
2.调整数据库配置：优化数据库配置以减少负载。
3.扩大binlog日志缓存：增加binlog日志缓存以缓解空间不足的问题。
4.调整数据同步线程限制：增加最大同步线程数以加速同步。
5.合并数据：如果遇到数据冲突，请检查数据并进行必要的解决方案，例如手动合并数据或重新导入数据。
6.使用GTID同步：使用GTID（全局事务标识符）可以帮助您跟踪数据同步，并帮助避免数据冲突。
7.使用监控工具：使用监控工具，例如MySQL Enterprise Monitor，可以帮助您实时监控数据同步状态并快速诊断问题
```
* mysql三高架构解析（高可用”、“高负载”、“高性能）
  * 单机方式
    * 一方面数据不安全，万一数据库的电脑磁盘坏了，就坑了。 另一方面数据库的并发能力是有限的，一般并发数200～500
  * 主从架构 （一主一从，一主多从）
    * 同步的方案有几种方案（异步、同步、半同步）
    ```
    主从方案的特点：
    1、解决了数据安全问题
    2、结合一些中间件（如：mycat）或工具（如：sharding-jdbc）实现读写分离；提高Mysql的整体性能/负载
    注：读写分离含义：数据的更新（即写请求）操作的是主Mysql，数据再同步到从Mysql中；读取数据（读请求）是访问的从Mysql。
    一主多从的方案中只有一个写节点（主mysql），一旦主Mysql出现问题，整个系统就无法进行写请求，那肯定是不行的。
    ```
  * MHA方案
    * 解决主节点的高可用问题。
    ```
    那MHA在主节点挂掉后，是怎么进行切换的？
    1、主节点挂了，在从节点中重新选举一个新备选主节点，原则是binlog最新最近更新的从节点作为新备选主节点。
    2、在备选主节点和其他从节点之间同步差异中继日志（relay log）
    3、应用从原来的主节点上保存二进制日志
    4、提升备选主节点为新主节点
    5、迁移集群其他从节点 作为 新主节点的 从节点。
    ```
  * PXC方案
    * 实现多个节点间的数据同步复制以及读写，并且可保障数据库的服务高可用及数据强一致性。
    ```
    PXC的原理其实在提交事务时，确保所有的节点事务都要成功提交，才返回成功；如果其中有一个不成功，就回滚数据，返回不成功
    确保数据肯定是一致的，而且是实时一致；当然这样就导致性能有损耗。PXC另一个好处就是每个节点都可以提供读写请求，不管写在哪个节点，都能够保证数据强一致性。
    ```
  > MHA与PXC
  >> 1、MHA主要写入速度很快，但数据不是强一致性
  2、PXC保证数据强一致性，但写入速度慢  
  >>> PXC适合存储高价值的数据，要求数据强一致性，如：账户，订单，交易等等  
  >>>  MHA适合存储低价值的数据，不要求强一致性，如：权限，通知，日志，商品数据，购物车等等
### redis
* 主从同步
  * 原理
```
从数据库连接主数据库，发送 SYNC 命令;
主数据库接收到 SYNC 命令后，可以执行 BGSAVE 命令生成 RDB 文件并使用缓冲区记录此后执行的所有写命令;
主数据库 BGSAVE 执行完后，向所有从数据库发送快照文件，并在发送期间继续记录被执行的写命令;
从数据库收到快照文件后丢弃所有旧数据，载入收到的快照;
主数据库快照发送完毕后开始向从数据库发送缓冲区中的写命令;
从数据库完成对快照的载入，开始接受命令请求，并执行来自主数据库缓冲区的写命令;(从数据库初始化完成)
主数据库每执行一个写命令就会向从数据库发送相同的写命令，从数据库接收并执行收到的写命令(从数据库初始化完成后的操作)
出现断开重连后，2.8 之后的版本会将断线期间的命令传给从数据库，增量复制。
主从刚刚连接的时候，进行全量同步;全同步结束后，进行增量同步。当然，如果有需要，slave 在任何时候都可以发起全量同步。Redis 的策略是，无论如何，首先会尝试进行增量同步，如不成功，要求从机进行全量同步。
```

优点
```
支持主从复制，主机会自动将数据同步到从机，可以进行读写分离;
为了分载 Master 的读操作压力，Slave 服务器可以为客户端提供只读操作的服务，写服务依然必须由 Master 来完成;
Slave 同样可以接受其他 Slaves 的连接和同步请求，这样可以有效地分载 Master 的同步压力;
Master 是以非阻塞的方式为 Slaves 提供服务。所以在 Master-Slave 同步期间，客户端仍然可以提交查询或修改请求;
Slave 同样是以阻塞的方式完成数据同步。在同步期间，如果有客户端提交查询请求，Redis 则返回同步之前的数据。
```
缺点
```
Redis 不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的 IP 才能恢复;
主机宕机，宕机前有部分数据未能及时同步到从机，切换 IP 后还会引入数据不一致的问题，降低了系统的可用性;
如果多个 Slave 断线了，需要重启的时候，尽量不要在同一时间段进行重启。因为只要 Slave 启动，就会发送 sync 请求和主机全量同步，当多个 Slave 重启的时候，可能会导致 Master IO 剧增从而宕机。
Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂;
redis 的主节点和从节点中的数据是一样的，降低的内存的可用性
```
* 哨兵模式
```
哨兵模式的具体工作机制：
在配置文件中通过 sentinel monitor <master-name> <ip> <redis-port> <quorum> 来定位master的IP、端口，一个哨兵可以监控多个master数据库，只需要提供多个该配置项即可。哨兵启动后，会与要监控的master建立两条连接：

一条连接用来订阅master的_sentinel_:hello频道与获取其他监控该master的哨兵节点信息
另一条连接定期向master发送INFO等命令获取master本身的信息

与master建立连接后，哨兵会执行三个操作：
定期（一般10s一次，当master被标记为主观下线时，改为1s一次）向master和slave发送INFO命令
定期向master和slave的_sentinel_:hello频道发送自己的信息
定期（1s一次）向master、slave和其他哨兵发送PING命令

发送INFO命令可以获取当前数据库的相关信息从而实现新节点的自动发现。所以说哨兵只需要配置master数据库信息就可以自动发现其slave信息。获取到slave信息后，哨兵也会与slave建立两条连接执行监控。通过INFO命令，哨兵可以获取主从数据库的最新信息，并进行相应的操作，比如角色变更等。
```
优点
```
哨兵模式是基于主从模式的，所有主从的优点，哨兵模式都具有。
主从可以自动切换，系统更健壮，可用性更高。
```
缺点 
```
具有主从模式的缺点，每台机器上的数据是一样的，内存的可用性较低。
Redis 较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。
```



* redis的持久化（RDB 和 AOF）
  RDB
```
RDB 持久化把当前进程数据生成快照（.rdb）文件保存到硬盘的过程，有手动触发和自动触发手动触发有 save 和 bgsave 两命令：
save 命令：阻塞当前 Redis，直到 RDB 持久化过程完成为止，若内存实例比较大会造成长时间阻塞，线上环境不建议用它
bgsave 命令：redis 进程执行 fork 操作创建子线程，由子线程完成持久化，阻塞时间很短（微秒级），是 save 的优化,在执行 redis-cli shutdown 关闭 redis 服务时，如果没有开启 AOF 持久化，自动执行 bgsave;
```
  * RDB 优点：
    * 压缩后的二进制文，适用于备份、全量复制，用于灾难恢复加载 RDB 恢复数据远快于 AOF 方式
    * 与 AOF 相比，在恢复大的数据集的时候，RDB 方式会更快一些。
    * 使用 bgsave 保存，交由子进程进行快照保存，父进程不需要再做其他 IO 操作，所以 RDB 持久化方式可以最大化 redis 的性能。
  * RDB 缺点：
    * 无法做到实时持久化，每次都要创建子进程，频繁操作成本过高
    * 保存后的二进制文件，存在老版本不兼容新版本 rdb 文件的问题
  AOF
```
AOF 持久化。　　打开 AOF 后， 每当 Redis 执行一个改变数据集的命令时（比如 SET）， 这个命令就会被追加到 AOF 文件的末尾。这样的话， 当 Redis 重新启时， 程序就可以通过重新执行 AOF 文件中的命令来达到重建数据集的目的。  

三种策略 always、everysec、no 对比
always： 不丢失数据 IO 开销大，一般 SATA 磁盘只有几百 TPS 每次有新命令追加到 AOF 文件时就执行一次 fsync ：非常慢，也非常安全。
everysec 每秒进行与 fsync：最多丢失 1 秒数据 可能丢失 1 秒数据 每秒 fsync 一次：足够快（和使用 RDB 持久化差不多），并且在故障时只会丢失 1 秒钟的数据。推荐（并且也是默认）的措施为每秒 fsync 一次， 这种 fsync 策略可以兼顾速度和安全性。
no 不用管 不可控 从不 fsync ：将数据交给操作系统来处理，由操作系统来决定什么时候同步数据。更快，也更不安全的选择。
```
  * AOF 的优点：
    * 使用 AOF 会让你的 Redis 更加耐久: 你可以使用不同的 fsync 策略：无 fsync，每秒 fsync，每次写的时候 fsync。使用默认的每秒 fsync 策略，Redis 的性能依然很好(fsync 是由后台线程进行处理的，主线程会尽力处理客户端请求)，一旦出现故障，你最多丢失 1 秒的数据。
    * AOF 文件是一个只进行追加的日志文件，即使由于某些原因(磁盘空间已满，写的过程中宕机等等)未执行完整的写入命令，你也也可使用 redis-check-aof 工具修复这些问题。
    * Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。
    * AOF 文件有序地保存了对数据库执行的所有写入操作， 这些写入操作以 Redis 协议的格式保存， 因此 AOF 文件的内容非常容易被人读懂， 对文件进行分析（parse）也很轻松。 导出（export） AOF 文件也非常简单： 举个例子， 如果你不小心执行了 FLUSHALL 命令， 但只要 AOF 文件未被重写， 那么只要停止服务器， 移除 AOF 文件末尾的 FLUSHALL 命令， 并重启 Redis ， 就可以将数据集恢复到 FLUSHALL 执行之前的状态。
  * AOF 的缺点
    * 对于相同的数据集来说，AOF 文件的体积通常要大于 RDB 文件的体积。
    * 根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）
 
###RabbitMQ
rabbitmq有三种模式：单机模式，普通集群模式，镜像集群模式
* 单机模式
  * 就是demo级别的，一般就是你本地启动了玩玩儿的，没人生产用单机模式
* 普通集群模式
```
意思就是在多台机器上启动多个rabbitmq实例，每个机器启动一个。但是你创建的queue，只会放在一个rabbtimq实例上，但是每个实例都同步queue的元数据。完了你消费的时候，实际上如果连接到了另外一个实例，那么那个实例会从queue所在实例上拉取数据过来。

这种方式确实很麻烦，也不怎么好，没做到所谓的分布式，就是个普通集群。因为这导致你要么消费者每次随机连接一个实例然后拉取数据，要么固定连接那个queue所在实例消费数据，前者有数据拉取的开销，后者导致单实例性能瓶颈。

而且如果那个放queue的实例宕机了，会导致接下来其他实例就无法从那个实例拉取，如果你开启了消息持久化，让rabbitmq落地存储消息的话，消息不一定会丢，得等这个实例恢复了，然后才可以继续从这个queue拉取数据。

所以这个事儿就比较尴尬了，这就没有什么所谓的高可用性可言了，这方案主要是提高吞吐量的，就是说让集群中多个节点来服务某个queue的读写操作。
```
* 镜像集群模式
```
这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。

这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue

那么怎么开启这个镜像集群模式呢？我这里简单说一下，避免面试人家问你你不知道，其实很简单rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。
```
* 镜像集群模式
```
这种模式，才是所谓的rabbitmq的高可用模式，跟普通集群模式不一样的是，你创建的queue，无论元数据还是queue里的消息都会存在于多个实例上，然后每次你写消息到queue的时候，都会自动把消息到多个实例的queue里进行消息同步。

这样的话，好处在于，你任何一个机器宕机了，没事儿，别的机器都可以用。坏处在于，第一，这个性能开销也太大了吧，消息同步所有机器，导致网络带宽压力和消耗很重！第二，这么玩儿，就没有扩展性可言了，如果某个queue负载很重，你加机器，新增的机器也包含了这个queue的所有数据，并没有办法线性扩展你的queue

那么怎么开启这个镜像集群模式呢？我这里简单说一下，避免面试人家问你你不知道，其实很简单rabbitmq有很好的管理控制台，就是在后台新增一个策略，这个策略是镜像集群模式的策略，指定的时候可以要求数据同步到所有节点的，也可以要求就同步到指定数量的节点，然后你再次创建queue的时候，应用这个策略，就会自动将数据同步到其他的节点上去了。
```
### kafka的高可用性
```
kafka一个最基本的架构认识：多个broker组成，每个broker是一个节点；你创建一个topic，这个topic可以划分为多个partition，每个partition可以存在于不同的broker上，每个partition就放一部分数据。

这就是天然的分布式消息队列，就是说一个topic的数据，是分散放在多个机器上的，每个机器就放一部分数据。

实际上rabbitmq之类的，并不是分布式消息队列，他就是传统的消息队列，只不过提供了一些集群、HA的机制而已，因为无论怎么玩儿，rabbitmq一个queue的数据都是放在一个节点里的，镜像集群下，也是每个节点都放这个queue的完整数据。

kafka 0.8以前，是没有HA机制的，就是任何一个broker宕机了，那个broker上的partition就废了，没法写也没法读，没有什么高可用性可言。

kafka 0.8以后，提供了HA机制，就是replica副本机制。每个partition的数据都会同步到吉他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower。写的时候，leader会负责把数据同步到所有follower上去，读的时候就直接读leader上数据即可。只能读写leader？很简单，要是你可以随意读写每个follower，那么就要care数据一致性的问题，系统复杂度太高，很容易出问题。kafka会均匀的将一个partition的所有replica分布在不同的机器上，这样才可以提高容错性。

这么搞，就有所谓的高可用性了，因为如果某个broker宕机了，没事儿，那个broker上面的partition在其他机器上都有副本的，如果这上面有某个partition的leader，那么此时会重新选举一个新的leader出来，大家继续读写那个新的leader即可。这就有所谓的高可用性了。

写数据的时候，生产者就写leader，然后leader将数据落地写本地磁盘，接着其他follower自己主动从leader来pull数据。一旦所有follower同步好数据了，就会发送ack给leader，leader收到所有follower的ack之后，就会返回写成功的消息给生产者。（当然，这只是其中一种模式，还可以适当调整这个行为）

消费的时候，只会从leader去读，但是只有一个消息已经被所有follower都同步成功返回ack的时候，这个消息才会被消费者读到。
```

* 如何保证消息不被重复消费（如何保证消息消费时的幂等性）？
```
首先就是比如rabbitmq、rocketmq、kafka，都有可能会出现消费重复消费的问题，正常。因为这问题通常不是mq自己保证的，是给你保证的。然后我们挑一个kafka来举个例子，说说怎么重复消费吧。

kafka实际上有个offset的概念，就是每个消息写进去，都有一个offset，代表他的序号，然后consumer消费了数据之后，每隔一段时间，会把自己消费过的消息的offset提交一下，代表我已经消费过了，下次我要是重启啥的，你就让我继续从上次消费到的offset来继续消费吧。

但是凡事总有意外，比如我们之前生产经常遇到的，就是你有时候重启系统，看你怎么重启了，如果碰到点着急的，直接kill进程了，再重启。这会导致consumer有些消息处理了，但是没来得及提交offset，尴尬了。重启之后，少数消息会再次消费一次。

其实重复消费不可怕，可怕的是你没考虑到重复消费之后，怎么保证幂等性。

给你举个例子吧。假设你有个系统，消费一条往数据库里插入一条，要是你一个消息重复两次，你不就插入了两条，这数据不就错了？但是你要是消费到第二次的时候，自己判断一下已经消费过了，直接扔了，不就保留了一条数据？

一条数据重复出现两次，数据库里就只有一条数据，这就保证了系统的幂等性

幂等性，我通俗点说，就一个数据，或者一个请求，给你重复来多次，你得确保对应的数据是不会改变的，不能出错。

那所以第二个问题来了，怎么保证消息队列消费的幂等性？

其实还是得结合业务来思考，我这里给几个思路：

（1）比如你拿个数据要写库，你先根据主键查一下，如果这数据都有了，你就别插入了，update一下好吧

（2）比如你是写redis，那没问题了，反正每次都是set，天然幂等性

（3）比如你不是上面两个场景，那做的稍微复杂一点，你需要让生产者发送每条数据的时候，里面加一个全局唯一的id，类似订单id之类的东西，然后你这里消费到了之后，先根据这个id去比如redis里查一下，之前消费过吗？如果没有消费过，你就处理，然后这个id写redis。如果消费过了，那你就别处理了，保证别重复处理相同的消息即可。

还有比如基于数据库的唯一键来保证重复数据不会重复插入多条，我们之前线上系统就有这个问题，就是拿到数据的时候，每次重启可能会有重复，因为kafka消费者还没来得及提交offset，重复数据拿到了以后我们插入的时候，因为有唯一键约束了，所以重复数据只会插入报错，不会导致数据库中出现脏数据
```
* 如何保证消息的可靠传输（如何处理消息丢失的问题）？
#### kafka
* 1.消费端弄丢了数据
```
唯一可能导致消费者弄丢数据的情况，就是说，你那个消费到了这个消息，然后消费者那边自动提交了offset，让kafka以为你已经消费好了这个消息，其实你刚准备处理这个消息，你还没处理，你自己就挂了，此时这条消息就丢咯。

这不是一样么，大家都知道kafka会自动提交offset，那么只要关闭自动提交offset，在处理完之后自己手动提交offset，就可以保证数据不会丢。但是此时确实还是会重复消费，比如你刚处理完，还没提交offset，结果自己挂了，此时肯定会重复消费一次，自己保证幂等性就好了

生产问题
生产环境碰到的一个问题，就是说我们的kafka消费者消费到了数据之后是写到一个内存的queue里先缓冲一下，结果有的时候，你刚把消息写入内存queue，然后消费者会自动提交offset。
然后此时我们重启了系统，就会导致内存queue里还没来得及处理的数据就丢失了

```
* 2.kafka弄丢了数据
```
就是kafka某个broker宕机，然后重新选举partiton的leader时。大家想想，要是此时其他的follower刚好还有些数据没有同步，结果此时leader挂了，然后选举某个follower成leader之后，他不就少了一些数据？这就丢了一些数据啊。

所以此时一般是要求起码设置如下4个参数：
给这个topic设置replication.factor参数：这个值必须大于1，要求每个partition必须有至少2个副本
在kafka服务端设置min.insync.replicas参数：这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系，没掉队，这样才能确保leader挂了还有一个follower吧
在producer端设置acks=all：这个是要求每条数据，必须是写入所有replica之后，才能认为是写成功了
在producer端设置retries=MAX（很大很大很大的一个值，无限次重试的意思）：这个是要求一旦写入失败，就无限重试，卡在这里了

我们生产环境就是按照上述要求配置的，这样配置之后，至少在kafka broker端就可以保证在leader所在broker发生故障，进行leader切换时，数据不会丢失
```
* 3.生产者会不会弄丢数据
```
如果按照上述的思路设置了ack=all，一定不会丢，要求是，你的leader接收到消息，
所有的follower都同步到了消息之后，才认为本次写成功了。
如果没满足这个条件，生产者会自动不断的重试，重试无限次。
```

#### rabbitmq
* 1.生产者将数据发送到rabbitmq的时候，可能数据就在半路给搞丢了，因为网络啥的问题，都有可能。
  * 1.1 可以选择用rabbitmq提供的事务功能 (吞吐量降低，因为太耗性能)
``` 
生产者发送数据之前开启rabbitmq事务（channel.txSelect），然后发送消息，如果消息没有成功被rabbitmq接收到，
那么生产者会收到异常报错，此时就可以回滚事务（channel.txRollback），然后重试发送消息；如果收到了消息，
那么可以提交事务（channel.txCommit）。但是问题是，rabbitmq事务机制一搞，基本上吞吐量会下来，因为太耗性能。
```
  * 1.2 生产者那里设置开启confirm模式
```
生产者那里设置开启confirm模式之后，你每次写的消息都会分配一个唯一的id，然后如果写入了rabbitmq中，
rabbitmq会给你回传一个ack消息，告诉你说这个消息ok了。如果rabbitmq没能处理这个消息，会回调你一个nack接口，
告诉你这个消息接收失败，你可以重试。而且你可以结合这个机制自己在内存里维护每个消息id的状态，如果超过一定时间还没接收到这个消息的回调，那么你可以重发。
```
***事务机制和cnofirm机制最大的不同在于，事务机制是同步的，你提交一个事务之后会阻塞在那儿，但是confirm机制是异步的，你发送个消息之后就可以发送下一个消息，然后那个消息rabbitmq接收了之后会异步回调你一个接口通知你这个消息接收到了***
* 2.rabbitmq弄丢了数据
  * 开启rabbitmq的持久化
```
设置持久化有两个步骤，第一个是创建queue的时候将其设置为持久化的，这样就可以保证rabbitmq持久化queue的元数据，
但是不会持久化queue里的数据；第二个是发送消息的时候将消息的deliveryMode设置为2，就是将消息设置为持久化的，
此时rabbitmq就会将消息持久化到磁盘上去。必须要同时设置这两个持久化才行，rabbitmq哪怕是挂了，再次重启，
也会从磁盘上重启恢复queue，恢复这个queue里的数据。

而且持久化可以跟生产者那边的confirm机制配合起来，只有消息被持久化到磁盘之后，才会通知生产者ack了，
所以哪怕是在持久化到磁盘之前，rabbitmq挂了，数据丢了，生产者收不到ack，你也是可以自己重发的。
```
* 3.消费端弄丢了数据
  * 3.1 用rabbitmq提供的ack机制
```
就是你关闭rabbitmq自动ack，可以通过一个api来调用就行，然后每次你自己代码里确保处理完的时候，
再程序里ack一把。这样的话，如果你还没处理完，不就没有ack？那rabbitmq就认为你还没处理完，
这个时候rabbitmq会把这个消费分配给别的consumer去处理，消息是不会丢的。
```
* 如何保证消息的顺序性？1.rabbitmq：一个queue，多个consumer (顺序会错乱)  2.kafka：一个topic，一个partition，一个consumer，内部多线程 (顺序会错乱)
  * rabbitmq：拆分多个queue，每个queue一个consumer，就是多一些queue而已 或者就一个queue但是对应一个consumer，然后这个consumer内部用内存队列做排队，然后分发给底层不同的worker来处理
  * kafka：一个topic，一个partition，一个consumer，内部单线程消费，写N个内存queue，然后N个线程分别消费一个内存queue即可
* 大量消息在mq里积压了几个小时了还没解决
```
一般这个时候，只能操作临时紧急扩容了，具体操作步骤和思路如下：
1）先修复consumer的问题，确保其恢复消费速度，然后将现有cnosumer都停掉
2）新建一个topic，partition是原来的10倍，临时建立好原先10倍或者20倍的queue数量
3）然后写一个临时的分发数据的consumer程序，这个程序部署上去消费积压的数据，消费之后不做耗时的处理，直接均匀轮询写入临时建立好的10倍数量的queue
4）接着临时征用10倍的机器来部署consumer，每一批consumer消费一个临时queue的数据
5）这种做法相当于是临时将queue资源和consumer资源扩大10倍，以正常的10倍速度来消费数据
6）等快速消费完积压数据之后，得恢复原先部署架构，重新用原先的consumer机器来消费消息
```
## 监控
* K8S集群中常用的 exporter 
```
1.kube-state-metrics：kube-state-metrics 收集关于 Kubernetes API 对象状态的指标，如节点、Pod、Service、Deployment 等。这些指标可以用于监控 Kubernetes 状态，同时提供了诊断信息。
2.node-exporter：node-exporter 用于收集与主机相关的指标数据，包括 CPU、内存、磁盘和网络等。它可以监控集群中每个节点的资源使用情况。
3.cAdvisor：cAdvisor 收集容器的指标数据，包括 CPU、内存、网络和文件系统使用情况。它可以帮助监控每个容器的资源使用情况和性能瓶颈。
4.kubelet-exporter：kubelet-exporter 从每个节点的 kubelet 中获取指标数据，包括容器、Pod 和节点级别的数据。它可以监控 Kubernetes 集群中的每个节点的资源使用情况和健康状况。
5.prometheus-operator：prometheus-operator 是一个用于管理 Prometheus 实例的工具，它可以自动化 Prometheus 实例的创建和配置。它可以自动发现 Kubernetes 集群中的服务、Pod 和节点，并将其用作 Prometheus 的目标
```

* 更改 Prometheus 的显示时区以及监控指标的时间戳转换为所需的时区
```
在 Prometheus 中更改显示时区可以通过设置环境变量 TZ 来实现。这个环境变量可以指定 Prometheus 使用的时区。

可以在以下网址中查找可用的时区列表：
https://en.wikipedia.org/wiki/List_of_tz_database_time_zones

如果您希望将监控指标的时间戳转换为所需的时区，请在查询和展示数据时使用 PromQL 的内置时间函数 timezone 或 offset。例如，如果您希望将时间戳转换为东八区，则可以使用以下查询：
sql
my_metric{job="my_job"} offset 8h

php
my_metric{job="my_job"} | timezone(offset: 8h)

这将返回一个时间戳相对于 UTC 偏移 8 小时的监控指标数据。

除了使用 time() 函数和 offset 修改器之外，还可以使用 Prometheus 提供的 label_replace 函数来实现时间戳转换。
这个函数可以用于修改指标标签的值，例如将时间戳标签的值从 UTC 转换为所需的时区

下面是一个使用 label_replace 函数将时间戳标签转换为东京标准时间（JST）的示例：
label_replace(metric, "time", "$1", "timestamp", "(.*)", "9")
这个表达式将名称为 metric 的指标中的 timestamp 标签替换为 time 标签，并将其值从 UTC 时间调整为 JST。
在这个表达式中，$1 表示从 timestamp 标签中提取的值。(.*) 表示匹配任意字符，用于提取 timestamp 标签中的值。
最后一个参数 "9" 表示 UTC 和 JST 之间的时差，即 9 个小时

```



## 网站
* 网站状态码 500 502 503 504 什么意思作为运维怎么去排查 分别怎么处理
```
500 状态码： Internal Server Error，服务器内部错误。
排查方法：检查服务器日志，确定错误的原因。
处理方法：更新代码，修复程序错误，或者重启服务器。

502 状态码：Bad Gateway，网关错误。
排查方法：检查网关的配置和连接，确定错误的原因。
处理方法：修复网关配置，重启网关或者服务器。

503 状态码：Service Unavailable，服务不可用。
排查方法：检查服务器资源是否不足，确定错误的原因。
处理方法：重启服务器，添加更多的资源，或者重新配置服务器。

504 状态码：Gateway Timeout，网关超时。
排查方法：检查网关的连接是否正常，确定错误的原因。
处理方法：重启网关或者服务器，或者修复网关的配置。

总的来说，对于这些状态码，我们需要分析错误的原因，检查相关服务器资源，并且采取相应的措施修复错误。
```


